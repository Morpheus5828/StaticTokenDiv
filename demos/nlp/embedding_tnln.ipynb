{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.261470900Z",
     "start_time": "2024-12-01T22:14:09.591174300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys, os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import static_token_div.tools.vocab_tools as vocab_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.274357800Z",
     "start_time": "2024-12-01T22:14:12.262471100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.317397500Z",
     "start_time": "2024-12-01T22:14:12.275358600Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    tokens = text.strip().split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.325404600Z",
     "start_time": "2024-12-01T22:14:12.289372200Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vocab(tokens):\n",
    "    vocab = {}\n",
    "    for word in tokens:\n",
    "        if word not in vocab.keys():\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.325404600Z",
     "start_time": "2024-12-01T22:14:12.305386100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.764404700Z",
     "start_time": "2024-12-01T22:14:12.320399800Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "file_path = \"../../resources/tlnl_tp1_data/alexandre_dumas/fusion.txt\"\n",
    "corpus = read_corpus(file_path)\n",
    "vocab = create_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.780420500Z",
     "start_time": "2024-12-01T22:14:12.763403200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "35428"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.932559Z",
     "start_time": "2024-12-01T22:14:12.780420500Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [vocab[word] for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.949576400Z",
     "start_time": "2024-12-01T22:14:12.933560900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2410384"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:12.994616Z",
     "start_time": "2024-12-01T22:14:12.949576400Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(data, k):\n",
    "    all_input = []\n",
    "    all_target = []\n",
    "    for idx in range(len(data) - k):\n",
    "        current_input = data[idx:idx + k]\n",
    "        all_input.append(current_input)\n",
    "        all_target.append(data[idx + k])\n",
    "    return all_input, all_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:15.183495500Z",
     "start_time": "2024-12-01T22:14:12.980604100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_data, y_data = extract_data(data, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:16.706658800Z",
     "start_time": "2024-12-01T22:14:15.183495500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1928303, 5]), torch.Size([1928303]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(torch.tensor(X_data), torch.tensor(y_data), test_size=0.2)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:16.715666900Z",
     "start_time": "2024-12-01T22:14:16.696647800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:16.756704600Z",
     "start_time": "2024-12-01T22:14:16.712664600Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, k, vocab_size, embed_dim=100):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(k * embed_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP(k=k, vocab_size=13023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:16.764712Z",
     "start_time": "2024-12-01T22:14:16.727677700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, X_train, y_train, X_test, y_test, device, batch_size=64, nb_epoch=10):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": []\n",
    "    }\n",
    "\n",
    "    num_samples = X_train.size(0)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(nb_epoch):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_Y = batch_Y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / num_batches\n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_Y in test_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_Y = batch_Y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_Y)\n",
    "\n",
    "                total_test_loss += loss.item()\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        history[\"test_loss\"].append(avg_test_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{nb_epoch}], train loss: {avg_train_loss:.4f}, test loss: {avg_test_loss:.4f}')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:16.764712Z",
     "start_time": "2024-12-01T22:14:16.743692500Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_words = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_Y = batch_Y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "\n",
    "            loss = criterion(outputs, batch_Y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_words += batch_Y.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_words\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:14:17.408042800Z",
     "start_time": "2024-12-01T22:14:16.759706900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP(k=k, vocab_size=len(vocab.keys())).to(device)\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters(), weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-12-01T22:14:17.407041800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], train loss: 4.8714, test loss: 4.4344\n",
      "Epoch [2/20], train loss: 4.2973, test loss: 4.1261\n",
      "Epoch [3/20], train loss: 4.0782, test loss: 3.9738\n",
      "Epoch [4/20], train loss: 3.9596, test loss: 3.8855\n",
      "Epoch [5/20], train loss: 3.8850, test loss: 3.8254\n",
      "Epoch [6/20], train loss: 3.8325, test loss: 3.7838\n",
      "Epoch [7/20], train loss: 3.7931, test loss: 3.7508\n",
      "Epoch [8/20], train loss: 3.7616, test loss: 3.7256\n",
      "Epoch [9/20], train loss: 3.7348, test loss: 3.7031\n"
     ]
    }
   ],
   "source": [
    "history = train(model, criterion, optimizer, X_train, y_train, X_test, y_test, device, batch_size=batch_size, nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "perplexity = calculate_perplexity(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history[\"train_loss\"], c=\"blue\", label=\"Train loss\")\n",
    "plt.plot(history[\"test_loss\"], c=\"orange\", label=\"Test loss\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(f\"Training loss, perplexity: {perplexity:.2f}\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Créer le vocabulaire inverse (index -> mot)\n",
    "inverse_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "def generate_words(model, vocab, inverse_vocab, input_words, n, k, device):\n",
    "    \"\"\"\n",
    "    Génère n mots à partir de k mots d'entrée.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Le modèle entraîné.\n",
    "        vocab (dict): Dictionnaire de vocabulaire (mot -> index).\n",
    "        inverse_vocab (dict): Dictionnaire inverse (index -> mot).\n",
    "        input_words (list of str): Liste des k mots d'entrée.\n",
    "        n (int): Nombre de mots à générer.\n",
    "        k (int): Nombre de mots d'entrée.\n",
    "        device (torch.device): Dispositif (CPU ou GPU).\n",
    "\n",
    "    Returns:\n",
    "        list of str: Liste des mots générés.\n",
    "    \"\"\"\n",
    "    model.eval()  # Mettre le modèle en mode évaluation\n",
    "    generated = []\n",
    "\n",
    "    # Vérifier que input_words a bien k mots\n",
    "    if len(input_words) != k:\n",
    "        raise ValueError(f\"Le nombre de mots d'entrée doit être {k}, mais {len(input_words)} ont été fournis.\")\n",
    "\n",
    "    # Convertir les mots d'entrée en indices\n",
    "    try:\n",
    "        input_indices = [vocab[word] for word in input_words]\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Le mot '{e.args[0]}' n'est pas dans le vocabulaire.\")\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Convertir en tenseur et ajouter une dimension batch\n",
    "        input_tensor = torch.tensor([input_indices], dtype=torch.long).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)  # Obtenir les logits\n",
    "            probabilities = torch.softmax(output, dim=1)  # Calculer les probabilités\n",
    "            predicted_idx = torch.argmax(probabilities, dim=1).item()  # Prendre l'indice avec la plus haute probabilité\n",
    "\n",
    "        # Convertir l'indice prédit en mot\n",
    "        predicted_word = inverse_vocab.get(predicted_idx, \"<UNK>\")\n",
    "        generated.append(predicted_word)\n",
    "\n",
    "        # Mettre à jour la séquence d'entrée\n",
    "        input_indices = input_indices[1:] + [predicted_idx]\n",
    "\n",
    "    return generated\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_words = [\"je\", \"suis\", \"un\", \"exemple\", \"de\"]  # Remplacez par vos propres mots d'entrée\n",
    "n = 10  # Nombre de mots à générer\n",
    "\n",
    "generated_words = generate_words(model, vocab, inverse_vocab, input_words, n, k, device)\n",
    "print(\"Mots générés :\", ' '.join(generated_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
